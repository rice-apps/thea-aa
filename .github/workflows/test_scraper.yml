name: Run Scraper Daily

on:
  push:
    branches:
      - scraper-tecq
  schedule:
    - cron: "*/5 * * * *" # Runs every 5 minutes
  workflow_dispatch: # Allows manual workflow trigger

jobs:
  run-scraper:
    runs-on: ubuntu-latest
    
    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.13'

      - name: Install Google Chrome
        run: |
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable

      - name: Verify Chrome Installation
        run: |
          which google-chrome
          google-chrome --version

      - name: Install ChromeDriver
        run: |
          sudo apt-get install -y chromium-chromedriver
          sudo ln -s /usr/lib/chromium-browser/chromedriver /usr/local/bin/chromedriver

      - name: Export Chrome Binary Path
        run: |
          echo "CHROME_BIN=$(which google-chrome)" >> $GITHUB_ENV

      - name: Install Python Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run Scraper
        env:
          CHROME_BIN: ${{ env.CHROME_BIN }}
        run: |
          python main.py

      - name: Save Excel Output
        run: |
          timestamp=$(date +"%Y-%m-%d_%H-%M-%S")
          mv output.xlsx "output_$timestamp.xlsx"
          mv "output_$timestamp.xlsx" results/

      - name: Commit and Push the Excel File
        run: |
          git config --local user.email "nn36@rice.edu"
          git config --local user.name "GitHub Actions"
          git add results/output_*.xlsx
          git commit -m "Add data for $timestamp"
          git push --force
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
