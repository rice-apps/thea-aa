name: Run Scraper Daily

on:
  push:
    branches:
      - scraper-tecq
  schedule:
    - cron: "*/5 * * * *" # Runs every 5 minutes
  workflow_dispatch: # Allows manual workflow trigger

jobs:
  run-scraper:
    runs-on: ubuntu-latest
    
    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.13'  # Use your required Python version

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      # Setup Chrome and ChromeDriver
      - name: Setup Chrome and ChromeDriver
        uses: browser-actions/setup-chrome@v1.7.2
        with:
          chrome-version: 120  # Match your target Chrome version
          install-chromedriver: true

      # Ensure CHROME_BIN and CHROMEDRIVER_PATH are exported
      - name: Export Chrome and ChromeDriver Paths
        run: |
          echo "CHROME_BIN=/usr/bin/google-chrome" >> $GITHUB_ENV
          echo "CHROMEDRIVER_PATH=$(which chromedriver)" >> $GITHUB_ENV

      # Run the scraper
      - name: Run Scraper
        env:
          CHROME_BIN: ${{ env.CHROME_BIN }}  # Pass Chrome binary path to your script
          CHROMEDRIVER_PATH: ${{ env.CHROMEDRIVER_PATH }}  # Pass ChromeDriver path to your script
        run: |
          python main.py
        
      - name: Save Excel Output
        # Create a file name with the date and time
        run: |
          timestamp=$(date +"%Y-%m-%d_%H-%M-%S")
          mv output.xlsx "output_$timestamp.xlsx"
          mv "output_$timestamp.xlsx" results/
        
      - name: Commit and Push the Excel file
        run: |
          git config --local user.email "nn36@rice.edu"
          git config --local user.name "GitHub Actions"
          git add results/output_*.xlsx
          git commit -m "Add data for $timestamp"
          git push --force
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
